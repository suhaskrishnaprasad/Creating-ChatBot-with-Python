{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zB8WDSDusRqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_JCsj9yrvVP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ],
      "metadata": {
        "id": "Du88NSA_rxB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "metadata": {
        "id": "_fWAx_Bkso1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "CTRoU7rnst5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)\n"
      ],
      "metadata": {
        "id": "lpC5P2fZtEW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "id": "Qo_MiBb_tRMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "YOQCz6oKtYoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "3oltFEdQtbjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "metadata": {
        "id": "02jGGPVJtcqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "metadata": {
        "id": "0k3Osx-ftehS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][2]"
      ],
      "metadata": {
        "id": "hvZ1dpWGtgDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = test_data + train_data"
      ],
      "metadata": {
        "id": "GozfvlS6tirq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data)"
      ],
      "metadata": {
        "id": "SLEe5SOptyU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "metadata": {
        "id": "ynUmD5NLt0_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "metadata": {
        "id": "x83cEj1fvl71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "qFFczm1vvnZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 # add an extra space to hold a 0 for Keras's pad_sequences"
      ],
      "metadata": {
        "id": "2iPL_bXbvpAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])  ##to check long story"
      ],
      "metadata": {
        "id": "Abgq2K38vscj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_story_len"
      ],
      "metadata": {
        "id": "plGwq5DmvuK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "metadata": {
        "id": "Wx2me3DHvv5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_question_len"
      ],
      "metadata": {
        "id": "trfOzv2zvxO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "QJAxk6Fl2jBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "metadata": {
        "id": "KRUDNgp_2i_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "7_Uhd_B92i8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "metadata": {
        "id": "CeOcL_rq2i6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "ak47jpo92i3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "FwLtE8av2i1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "metadata": {
        "id": "HYRZE0gW2iyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_text)"
      ],
      "metadata": {
        "id": "UzFDTLlv2iwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_seq)"
      ],
      "metadata": {
        "id": "cdZ4c0_B2itD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "  # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "\n",
        "\n",
        "    for story, query, answer in data:\n",
        "\n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "\n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "\n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "\n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "\n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "metadata": {
        "id": "eiR949n-2irL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "metadata": {
        "id": "HZwGUGig2inW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "metadata": {
        "id": "2lMzPbod2ilj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_test"
      ],
      "metadata": {
        "id": "RNeOpIL-2iho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries_test"
      ],
      "metadata": {
        "id": "APy5dHRG2if4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers_test"
      ],
      "metadata": {
        "id": "aIX_xm_p2iYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(answers_test)"
      ],
      "metadata": {
        "id": "ZxTwE8yQ2iLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "metadata": {
        "id": "LJuNRZN23RPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['no']"
      ],
      "metadata": {
        "id": "mo8BO4vk3SFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "KkBtk-covyhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "metadata": {
        "id": "5wlHsWQf1OFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(vocab)+1"
      ],
      "metadata": {
        "id": "RMeaBpTO1sQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "r_4-De8w1PvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "8dXiSIKs1dB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "p_9hOBED1ets"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "metadata": {
        "id": "DMHVWZti1wu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "metadata": {
        "id": "UcoXbv8S1y_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])\n",
        "response = Permute((2, 1))(response)"
      ],
      "metadata": {
        "id": "F1eB7F4D10X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "metadata": {
        "id": "quBSFRly12zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "metadata": {
        "id": "Ipjn5koQ14Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "metadata": {
        "id": "_mzmEKLD17Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Dgsr3NWC185y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Z1wOxTW_1-ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "history = model.fit([input_train, querie_train], answer_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "metadata": {
        "id": "4OIVw-Wm1_4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ],
      "metadata": {
        "id": "zOaD8iEh2DJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A1rQnJHR3Zyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "metadata": {
        "id": "BIsnjFns3ZxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0][0]"
      ],
      "metadata": {
        "id": "dsX9vemm3Zna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "metadata": {
        "id": "Tc6Olfu43ZjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "metadata": {
        "id": "wR_PJckD3Zhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "metadata": {
        "id": "LqoENTab3ZeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "id": "A0L0dJMc3ZcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing Your Own Stories and Questions\n",
        "(note:words should be from vocab itself)"
      ],
      "metadata": {
        "id": "xRxOhxOM3xXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "6EmXLSoO3ZNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "metadata": {
        "id": "jitVCEiu37P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "metadata": {
        "id": "kHNN7tNx39Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question.split()"
      ],
      "metadata": {
        "id": "TSL8oVlF3_WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "metadata": {
        "id": "MsCWIRnE4Aix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "aO3EgUut4CNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "czMvCWL_4DZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "id": "oXAbTjo64Fzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD2-lDnO4H8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}